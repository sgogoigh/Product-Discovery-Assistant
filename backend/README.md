# AI Product Discovery Assistant Backend

This is the **FastAPI backend** for the AI Product Discovery Assistant project. It provides RESTful APIs for product management, scraping, and a RAGâ€‘powered chatbot interface. The backend is designed to be modular, extensible, and productionâ€‘ready.

---

## Project Structure
```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPI entrypoint
â”‚   â”‚   â”œâ”€â”€ config.py              # Env vars, DB connection settings
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py        # SQLAlchemy engine + session
â”‚   â”‚   â”‚   â”œâ”€â”€ models.py          # Product schema (ORM models)
â”‚   â”‚   â”‚   â”œâ”€â”€ crud.py            # DB operations (insert, query)
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ routes_products.py # REST endpoints for products
â”‚   â”‚   â”‚   â”œâ”€â”€ routes_chat.py     # Chatbot endpoint (RAG pipeline)
â”‚   â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.py         # Scraping logic for chosen site
â”‚   â”‚   â”‚   â”œâ”€â”€ utils.py           # Cleaning, validation helpers
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ chunking.py      # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py      # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest.py      # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts.py      # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ reasoning.py      # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ retrieval.py      # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_store.py      # Embedding generation
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.py          # Logging setup
â”‚   â”‚   â”‚   â”œâ”€â”€ exceptions.py      # Custom error handling
â”‚   â”‚   â””â”€â”€ tests/
â”‚   â”‚       â”œâ”€â”€ test_scraper.py
â”‚   â”‚       â”œâ”€â”€ test_api.py
â”‚   â”‚       â”œâ”€â”€ test_rag.py
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt           # Python deps
â”‚   â”œâ”€â”€ Dockerfile                 # Containerization
â”‚   â””â”€â”€ README.md                  # Documentation
```

---

## Features

- **Product API**
  - `POST /api/products/` â†’ Create product
  - `GET /api/products/` â†’ List products
  - `GET /api/products/{id}` â†’ Get product by ID
  - `PUT /api/products/{id}` â†’ Full update
  - `PATCH /api/products/{id}` â†’ Partial update
  - `DELETE /api/products/{id}` â†’ Delete product

- **Scraping**
  - `scraper.py` fetches product data from target sites
  - `utils.py` cleans and validates scraped data

- **RAG Pipeline**
  - Chunking, embeddings, retrieval, reasoning
  - Chatbot endpoint (`routes_chat.py`) integrates with vector store

- **Utilities**
  - Centralized logging
  - Custom exception handling

- **Testing**
  - Pytest suite for API, scraper, and RAG modules

---

## Prerequisites

- Python 3.11+
- PostgreSQL (local or remote)
- pip / venv
- (Optional) Docker & Docker Compose

---

## Running Locally

### 1. Clone the repo
```bash
git clone https://github.com/yourusername/neusearch.git
cd neusearch/backend
```

### 2. Create a Virtual Environment
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3. Install Dependencies
```bash
python install -r requirements.txt
```

### 4. Configure Environment variables
Create a ```.env``` file in ```backend/```
```bash
DATABASE_URL=postgresql://user:password@localhost:5432/neusearch
GEMINI_API_KEY=your_openai_key_here
PINECONE_API_KEY=your_pinecone_key_here
PINECONE_INDEX=your_index_name
PINECONE_CLOUD=aws
PINECONE_REGION=your_index_deployment_region
EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
```

### 5. Run Migrations (if using Alembic)
```bash
alembic upgrade head
```

### 6. Start FASTApi Server
```bash
uvicorn app.main:app --reload
```

Server runs at:
ðŸ‘‰ http://127.0.0.1:8000 <br>
Interactive docs: ðŸ‘‰ http://127.0.0.1:8000/docs


## Running Tests
```bash
pytest -v
```
This runs the suite in app/tests/ to validate API, scraper, and RAG pipeline.

## Running with Docker
### 1. Build Image
```bash
docker build -t neusearch-backend .
```

### 2. Run Container
```bash
docker run -p 8000:8000 --env-file .env neusearch-backend
```

<hr>

## Example Usage
### Create a product
```bash
curl -X POST "http://127.0.0.1:8000/api/products/" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Zen Skort",
    "price": 1899,
    "description": "Comfortable skort",
    "category": "Skorts",
    "image_url": "https://hunnit.com/cdn/shop/products/skort.jpg",
    "source_url": "https://hunnit.com/products/zen-skort",
    "features": [
      {"section": "Fabric", "title": "Soft", "description": "Feels great"}
    ]
  }'
```

### Get all products
```bash
curl "http://127.0.0.1:8000/api/products/"
```

<hr>
> Made by Sunny Gogoi